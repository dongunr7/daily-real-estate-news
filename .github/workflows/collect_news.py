# collect_news.py
import os
import requests
from datetime import datetime, timedelta
import json
from anthropic import Anthropic
from bs4 import BeautifulSoup

class RealEstateNewsCollector:
    def __init__(self):
        self.anthropic_client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
        self.today = datetime.now().strftime('%Yë…„ %mì›” %dì¼')
        self.yesterday = (datetime.now() - timedelta(days=1)).strftime('%Yë…„ %mì›” %dì¼')
        
    def search_web(self, query):
        """ì›¹ ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜ - ì‹¤ì œë¡œëŠ” ì£¼ìš” ë‰´ìŠ¤ ì‚¬ì´íŠ¸ í¬ë¡¤ë§"""
        news_sites = [
            'https://news.daum.net/estate',
            'https://www.asiae.co.kr/list/real-estate',
            'https://www.fnnews.com/section/002003000'
        ]
        
        news_data = []
        for site in news_sites:
            try:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }
                response = requests.get(site, timeout=10, headers=headers)
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # ê°„ë‹¨í•œ ë‰´ìŠ¤ ì œëª© ì¶”ì¶œ ë¡œì§
                titles = soup.find_all(['h1', 'h2', 'h3', 'h4'], limit=10)
                for title in titles:
                    text = title.get_text().strip()
                    if any(keyword in text for keyword in ['ë¶€ë™ì‚°', 'ì•„íŒŒíŠ¸', 'ì§‘ê°’', 'ì¬ê±´ì¶•', 'ë¶„ì–‘']):
                        news_data.append({
                            'title': text,
                            'source': site,
                            'date': self.today
                        })
            except Exception as e:
                print(f"Error fetching {site}: {e}")
                
        return news_data
    
    def analyze_news_with_claude(self, news_data):
        """Claude APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ë¶„ì„"""
        prompt = f"""
        ë‹¤ìŒì€ {self.yesterday}ë¶€í„° {self.today}ê¹Œì§€ì˜ ë¶€ë™ì‚° ê´€ë ¨ ë‰´ìŠ¤ ë°ì´í„°ì…ë‹ˆë‹¤:
        
        {json.dumps(news_data, ensure_ascii=False, indent=2)}
        
        ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ê¸°ì¤€ì— ë§ì¶° 5ê°œì˜ ì£¼ìš” ë¶€ë™ì‚° ë‰´ìŠ¤ë¥¼ ì„ ì •í•˜ê³  ì •ë¦¬í•´ì£¼ì„¸ìš”:
        
        1. ì„ í˜¸ ë§¤ì²´: ë§¤ì¼ê²½ì œ, í•œêµ­ê²½ì œ, ì„œìš¸ê²½ì œ, ì¡°ì„ ì¼ë³´, ì¤‘ì•™ì¼ë³´, ë™ì•„ì¼ë³´, í•œê²¨ë ˆ, ê²½í–¥ì‹ ë¬¸, ì—°í•©ë‰´ìŠ¤, ë‰´ì‹œìŠ¤, ì¡°ì„ ë¹„ì¦ˆ, ë¨¸ë‹ˆíˆ¬ë°ì´, íŒŒì´ë‚¸ì…œë‰´ìŠ¤, KBS, SBS, MBC
        2. ê³µí†µì ìœ¼ë¡œ ë§ì´ ì–¸ê¸‰ëœ ì£¼ì œë³„ë¡œ 5ê°œ ì„ ì • (ê²¹ì¹˜ì§€ ì•Šê²Œ)
        3. ê°ê° ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬:
           - ê¸°ì‚¬ì œëª©
           - ë³¸ë¬¸ ìš”ì•½ (3-4ì¤„)
           - ë‚ ì§œ
           - ì¶œì²˜
        
        ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = self.anthropic_client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=2000,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text
        except Exception as e:
            print(f"Claude API error: {e}")
            return f"ë‰´ìŠ¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
    
    def send_slack_notification(self, content):
        """Slackìœ¼ë¡œ ê²°ê³¼ ì „ì†¡"""
        webhook_url = os.getenv('SLACK_WEBHOOK_URL')
        
        if not webhook_url:
            print("SLACK_WEBHOOK_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            return
        
        # Slack ë©”ì‹œì§€ í˜•ì‹
        slack_data = {
            "text": f"ğŸ“Š ì¼ì¼ ë¶€ë™ì‚° ë‰´ìŠ¤ ë¸Œë¦¬í•‘ - {self.today}",
            "blocks": [
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f"*ğŸ“Š {self.today} ë¶€ë™ì‚° ë‰´ìŠ¤ ë¸Œë¦¬í•‘*"
                    }
                },
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": content[:3000] + ("..." if len(content) > 3000 else "")
                    }
                }
            ]
        }
        
        try:
            response = requests.post(webhook_url, json=slack_data)
            if response.status_code == 200:
                print("âœ… Slack ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ!")
            else:
                print(f"âŒ Slack ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
                print(f"ì‘ë‹µ: {response.text}")
        except Exception as e:
            print(f"âŒ Slack ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def save_to_file(self, content):
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        with open('news_output.md', 'w', encoding='utf-8') as f:
            f.write(f"# ì¼ì¼ ë¶€ë™ì‚° ë‰´ìŠ¤ ë¸Œë¦¬í•‘ - {self.today}\n\n")
            f.write(content)
    
    def run(self):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print(f"ë¶€ë™ì‚° ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘ - {self.today}")
        
        # 1. ì›¹ì—ì„œ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
        print("ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        news_data = self.search_web("ë¶€ë™ì‚° ë‰´ìŠ¤")
        
        # 2. Claudeë¡œ ë‰´ìŠ¤ ë¶„ì„ ë° ì •ë¦¬
        print("Claudeë¡œ ë‰´ìŠ¤ ë¶„ì„ ì¤‘...")
        analyzed_content = self.analyze_news_with_claude(news_data)
        
        # 3. íŒŒì¼ë¡œ ì €ì¥
        self.save_to_file(analyzed_content)
        
        # 4. Slackìœ¼ë¡œ ì „ì†¡
        print("Slack ì•Œë¦¼ ì „ì†¡ ì¤‘...")
        self.send_slack_notification(analyzed_content)
        
        print("ì‘ì—… ì™„ë£Œ!")

if __name__ == "__main__":
    collector = RealEstateNewsCollector()
    collector.run()
